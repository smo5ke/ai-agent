"""
ğŸ”Œ LLM IPC Client
==================
ÙˆØ§Ø¬Ù‡Ø© Ù„Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ù€ LLM Worker Process Ø¹Ø¨Ø± TCP Socket.
"""

import socket
from multiprocessing.connection import Client
from typing import Optional

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª (ÙŠØ¬Ø¨ Ø£Ù† ØªØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ worker_process.py)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ADDRESS = ('localhost', 6000)
AUTHKEY = b"jarvis"
DEFAULT_TIMEOUT = 30  # Ø«ÙˆØ§Ù†ÙŠ


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def is_worker_available() -> bool:
    """ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù€ Worker Ù…ØªØ§Ø­"""
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(1)
        result = sock.connect_ex(ADDRESS)
        sock.close()
        return result == 0
    except:
        return False


def think(prompt: str, app_context: str = "", timeout: int = DEFAULT_TIMEOUT) -> dict:
    """
    Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨ Ù„Ù„Ù€ LLM Worker ÙˆØ§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ø±Ø¯.
    
    Args:
        prompt: Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„Ù‡
        app_context: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
        timeout: Ù…Ù‡Ù„Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ
    
    Returns:
        dict: Ø§Ù„Ù†ØªÙŠØ¬Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:
            - success: True/False
            - response: Ø§Ù„Ù€ JSON Ø§Ù„Ù…Ø­Ù„Ù„ (Ø¥Ø°Ø§ Ù†Ø¬Ø­)
            - error: Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£ (Ø¥Ø°Ø§ ÙØ´Ù„)
    """
    
    # ÙØ­Øµ ØªÙˆÙØ± Ø§Ù„Ù€ Worker
    if not is_worker_available():
        return {
            "success": False,
            "error": "LLM Worker ØºÙŠØ± Ù…ØªØµÙ„. ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„Ù‡: python llm/worker_process.py"
        }
    
    try:
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„
        conn = Client(ADDRESS, authkey=AUTHKEY)
        
        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
        request = {
            "prompt": prompt,
            "app_context": app_context
        }
        conn.send(request)
        
        # Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ø±Ø¯ Ù…Ø¹ timeout
        if conn.poll(timeout):
            result = conn.recv()
            conn.close()
            return result
        else:
            conn.close()
            return {
                "success": False,
                "error": f"Ø§Ù†ØªÙ‡Øª Ø§Ù„Ù…Ù‡Ù„Ø© ({timeout} Ø«Ø§Ù†ÙŠØ©) - Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ø·ÙŠØ¡ Ø¬Ø¯Ø§Ù‹"
            }
            
    except ConnectionRefusedError:
        return {
            "success": False,
            "error": "Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ LLM Worker. Ù‡Ù„ Ù‡Ùˆ Ù‚ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„ØŸ"
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {str(e)}"
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    print("ğŸ§ª Testing LLM IPC...")
    
    if is_worker_available():
        print("âœ… Worker is available!")
        result = think("Ø§ÙØªØ­ ÙƒØ±ÙˆÙ…", "chrome, notepad, calc")
        print(f"ğŸ“¤ Result: {result}")
    else:
        print("âŒ Worker is not available. Start it with: python llm/worker_process.py")
