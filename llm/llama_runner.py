# llm/llama_runner.py
"""
ğŸ§  LLM Planner v5.1 - Ø§Ù„Ø¯Ù…Ø§Øº Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ (Safe Mode)
Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¢Ù…Ù†Ø© Ø¬Ø¯Ø§Ù‹ Ù„ØªØ¬Ù†Ø¨ Access Violation
uses Llama-3.1
"""
import json
import os
import re
from pathlib import Path
from typing import Optional


class LLMPlanner:
    """Ø§Ù„Ù…Ø®Ø·Ø· Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LLaMA"""
    
    def __init__(self, model_path: str):
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"âŒ Model not found: {model_path}")
        
        print(f"ğŸ§  Loading Real Brain: {os.path.basename(model_path)}...")
        print("â³ Please wait... (Safe CPU Mode)")
        
        try:
            from llama_cpp import Llama
            
            # ğŸ”¥ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªØ·Ø§Ø¨Ù‚Ø© Ù…Ø¹ verify_model.py Ø§Ù„Ø°ÙŠ Ù†Ø¬Ø­
            self.llm = Llama(
                model_path=model_path,
                n_gpu_layers=0,      # CPU ONLY
                n_ctx=2048,          # Ø­Ø¬Ù… Ø°Ø§ÙƒØ±Ø© Ù…Ø¹Ù‚ÙˆÙ„
                n_threads=4,         # Ø¹Ø¯Ø¯ Ø£Ù†ÙˆÙŠØ© Ø¢Ù…Ù†
                n_batch=512,         
                verbose=False,       # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¶Ø¬ÙŠØ¬
                use_mmap=True,       # ØªÙØ¹ÙŠÙ„ mmap (Ù†Ø¬Ø­ ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±)
                use_mlock=False
            )
            
            self.system_prompt = self._load_prompt()
            print("âœ… Brain Loaded & Ready!")
            
        except Exception as e:
            print(f"âŒ Llama Init Error: {e}")
            raise

    def _load_prompt(self) -> str:
        prompt_path = Path(__file__).parent / "system_prompt.txt"
        if prompt_path.exists():
            return prompt_path.read_text(encoding="utf-8")
        return "You are an AI assistant. Output JSON only."

    def plan(self, user_input: str, memory_context: str = "") -> dict:
        # Ø¨Ù†Ø§Ø¡ prompt
        full_prompt = f"""<|start_header_id|>system<|end_header_id|>

{self.system_prompt}

MEMORY CONTEXT:
{memory_context if memory_context else "No context."}

<|eot_id|><|start_header_id|>user<|end_header_id|>

{user_input}

<|eot_id|><|start_header_id|>assistant<|end_header_id|>"""
        
        print("ğŸ¤” Thinking...")
        
        try:
            output = self.llm(
                full_prompt,
                max_tokens=1024,
                temperature=0.1,
                stop=["<|eot_id|>"]
            )
            
            raw_text = output["choices"][0]["text"].strip()
            print(f"ğŸ“¤ Raw output available")
            return self._extract_json(raw_text)
            
        except Exception as e:
            print(f"âŒ Inference Error: {e}")
            return {"steps": []}

    def _extract_json(self, text: str) -> dict:
        text = text.strip()
        # ØªÙ†Ø¸ÙŠÙ Ø¥Ø¶Ø§ÙÙŠ Ù„ÙˆØ³ÙˆÙ… Llama
        text = text.replace("<|eot_id|>", "").strip()
        
        # 1. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† JSON block (Ù‚Ø§Ø¦Ù…Ø© Ø£Ùˆ Ù‚Ø§Ù…ÙˆØ³)
        # Ù‡Ø°Ø§ regex ÙŠØ¨Ø­Ø« Ø¹Ù† Ø£ÙˆÙ„ [ ... ] Ø£Ùˆ { ... } ÙˆÙŠØ­Ø§ÙˆÙ„ Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¯Ø§Ø®Ù„Ù‡
        # Ù†Ø³ØªØ®Ø¯Ù… [\\s\\S]*? Ù„ÙŠÙƒÙˆÙ† non-greedy ÙˆÙŠÙ„ØªÙ‚Ø· Ø£ÙˆÙ„ Ø¨Ù„ÙˆÙƒ ØµØ­ÙŠØ­
        
        candidates = []
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù‚Ø§Ø¦Ù…Ø© []
        list_matches = list(re.finditer(r'\[[\s\S]*\]', text))
        if list_matches:
             # Ù†Ø£Ø®Ø° Ø¢Ø®Ø± ÙˆØ§Ø­Ø¯ ØºØ§Ù„Ø¨Ø§Ù‹ Ù„Ø£Ù†Ù‡ Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù‡Ù†Ø§Ùƒ Ø£Ù…Ø«Ù„Ø© ÙÙŠ Ø§Ù„ØªÙÙƒÙŠØ±ØŒ Ù„ÙƒÙ† Ø³Ù†Ø­Ø§ÙˆÙ„ Ø¨Ø°ÙƒØ§Ø¡
             # Ø¹Ø§Ø¯Ø© Ø§Ù„Ù€ JSON Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙŠÙƒÙˆÙ† ÙÙŠ Ø¢Ø®Ø± Ø§Ù„Ù†Øµ
             pass

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† JSON ÙƒÙ€ Code Block Ø¥Ø°Ø§ ÙˆØ¬Ø¯
        code_block = re.search(r'```json([\s\S]*?)```', text, re.IGNORECASE)
        if code_block:
            json_text = code_block.group(1).strip()
            try:
                data = json.loads(json_text)
                if isinstance(data, list): return {"steps": data}
                if isinstance(data, dict) and "steps" in data: return data
                if isinstance(data, dict): return {"steps": [data]} # Single action
            except:
                pass

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù‚ÙˆØ§Ø³ Ù…Ø¨Ø§Ø´Ø±Ø©
        # Ù†Ø­Ø§ÙˆÙ„ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙˆØ³Ø¹ Ù†Ø·Ø§Ù‚ Ù…Ù…ÙƒÙ† ÙŠØ¨Ø¯Ø£ Ø¨Ù€ [ ÙˆÙŠÙ†ØªÙ‡ÙŠ Ø¨Ù€ ]
        try:
            start_index = text.find('[')
            end_index = text.rfind(']')
            if start_index != -1 and end_index != -1 and end_index > start_index:
                json_str = text[start_index:end_index+1]
                return {"steps": json.loads(json_str)}
        except:
            pass
            
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø£Ø®ÙŠØ±Ø© Ù…Ø¹ {}
        try:
            start_index = text.find('{')
            end_index = text.rfind('}')
            if start_index != -1 and end_index != -1 and end_index > start_index:
                json_str = text[start_index:end_index+1]
                data = json.loads(json_str)
                if "steps" in data: return data
                return {"steps": [data]}
        except:
            pass

        print(f"âš ï¸ Could not parse JSON from: {text[:100]}...")
        return {"steps": []}
# ===== ÙˆØ¶Ø¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙˆÙ‡Ù…ÙŠ =====

def plan_mock(text: str) -> dict:
    """Ù†Ø³Ø®Ø© ÙˆÙ‡Ù…ÙŠØ© - Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø³Ø±ÙŠØ¹ ÙÙ‚Ø·"""
    return {
        "steps": [
            {"action": "create_folder", "params": {"name": "ØªØ¬Ø±Ø¨Ø©"}},
            {"action": "create_file", "params": {"name": "a.txt"}},
            {"action": "write_text", "params": {"file": "a.txt", "text": "Ù…Ø±Ø­Ø¨Ø§"}}
        ]
    }


def plan(text: str) -> dict:
    """Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© ØªÙØ³ØªØ®Ø¯Ù… Ø¹Ù†Ø¯Ù…Ø§ Ù„Ø§ ÙŠÙˆØ¬Ø¯ planner"""
    return plan_mock(text)
