# brain_server.py
"""
ğŸ§  Brain Server
ÙŠÙØµÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ù„ØªØ¬Ù†Ø¨ ØªØ¹Ø§Ø±Ø¶ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
"""
import sys
import json
import os
from http.server import BaseHTTPRequestHandler, HTTPServer
from llm.llama_runner import LLMPlanner

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
PORT = 5000
MODEL_PATH = "Meta-Llama-3.1-8B-Instruct-Q6_K_L.gguf"

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø¨Ø¯Ø¡
print(f"ğŸ§  Server: Loading model from {MODEL_PATH}...")
try:
    planner = LLMPlanner(model_path=MODEL_PATH)
    print("âœ… Server: Brain Ready!")
except Exception as e:
    print(f"âŒ Server: Failed to load brain: {e}")
    planner = None

class RequestHandler(BaseHTTPRequestHandler):
    def do_POST(self):
        if self.path == '/plan':
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            
            try:
                data = json.loads(post_data.decode('utf-8'))
                user_input = data.get('input', '')
                memory_context = data.get('context', '')
                
                print(f"ğŸ“© Server: Received request: {user_input[:50]}...")
                
                if planner:
                    result = planner.plan(user_input, memory_context)
                else:
                    result = {"steps": [], "error": "Model not loaded"}
                
                response = json.dumps(result).encode('utf-8')
                
                self.send_response(200)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                self.wfile.write(response)
                
            except Exception as e:
                self.send_response(500)
                self.end_headers()
                self.wfile.write(str(e).encode('utf-8'))

def run():
    server_address = ('', PORT)
    httpd = HTTPServer(server_address, RequestHandler)
    print(f"ğŸš€ Server: Listening on port {PORT}...")
    httpd.serve_forever()

if __name__ == '__main__':
    run()
