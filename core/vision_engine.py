# core/vision_engine.py
"""
ğŸ‘ï¸ Vision Engine - Ø¹ÙŠÙˆÙ† Ø¬Ø§Ø±ÙÙŠØ³ (Powered by Ollama)
ÙŠØ³ØªØ®Ø¯Ù… Ù†Ù…ÙˆØ°Ø¬ llama3.2-vision Ù„Ù‚Ø±Ø§Ø¡Ø© ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø¨Ø¹Ù…Ù‚.
"""
import os
import pyautogui
from pathlib import Path

# Dependency Check
try:
    import ollama
    OLLAMA_AVAILABLE = True
except ImportError:
    OLLAMA_AVAILABLE = False
    print("âŒ Ollama library not found. Run: pip install ollama")

class VisionEngine:
    def __init__(self, model="llama3.2-vision"):
        self.model = model
        self.ready = OLLAMA_AVAILABLE

    def capture_screen(self, save_path: str = "screen_shot.png") -> str:
        """Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø© Ù„Ù„Ø´Ø§Ø´Ø©"""
        try:
            screenshot = pyautogui.screenshot()
            screenshot.save(save_path)
            return save_path
        except Exception as e:
            print(f"âŒ Screenshot failed: {e}")
            return None

    def analyze_image(self, image_path: str, user_prompt: str = "Describe this image in detail") -> str:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø±Ø¤ÙŠØ©"""
        if not self.ready:
            return "âŒ Vision system is not ready (Ollama library missing)."
            
        if not os.path.exists(image_path):
            return f"âŒ Image not found: {image_path}"

        try:
            print(f"ğŸ‘ï¸ Analyzing image with {self.model}...")
            response = ollama.chat(
                model=self.model,
                messages=[{
                    'role': 'user',
                    'content': user_prompt,
                    'images': [image_path]
                }]
            )
            return response['message']['content']
        except Exception as e:
            return f"âŒ Vision Analysis Error: {e}\n(Make sure Ollama is running and 'llama3.2-vision' is pulled)"

    def see_screen(self) -> str:
        """Ø§Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø­ÙŠØ©: ØªØµÙˆÙŠØ± Ø§Ù„Ø´Ø§Ø´Ø© ÙˆÙˆØµÙ Ù…Ø­ØªÙˆÙŠØ§ØªÙ‡Ø§"""
        path = self.capture_screen()
        if path:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØµÙ Ø¯Ù‚ÙŠÙ‚ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
            prompt = "What do you see on this screen? If there is text, read it. If there is an error, explain it."
            description = self.analyze_image(path, prompt)
            
            # ØªÙ†Ø¸ÙŠÙ
            try:
                os.remove(path)
            except:
                pass
                
            return description
        return "Failed to capture screen."

    # Legacy alias for backward compatibility (optional)
    def read_image(self, image_path: str) -> str:
        return self.analyze_image(image_path, "Extract all text from this image exactly as it appears.")

if __name__ == "__main__":
    vision = VisionEngine()
    if vision.ready:
        print("ğŸ‘ï¸ Vision Ready via Ollama.")
        # Test if user wants to run a quick test
        # print(vision.see_screen())
    else:
        print("âŒ Vision not ready.")
